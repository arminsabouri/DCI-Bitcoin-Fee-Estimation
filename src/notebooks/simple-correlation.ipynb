{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "txs = pd.read_pickle('../../data/transactions-v4.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the columns\n",
    "print(txs.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple questions to ensure our data is sane before we start building models\n",
    "\n",
    "# 1. How many transactions are in the dataset?\n",
    "print(f\"Number of transactions: {len(txs)}\")\n",
    "\n",
    "# 2. What is the average wait time?\n",
    "avg_waittime = txs['waittime'].mean()\n",
    "print(f\"Average wait time: {int(avg_waittime)} seconds, {int(avg_waittime/60)} minutes\")\n",
    "\n",
    "# Median wait time\n",
    "median_waittime = txs['waittime'].median()\n",
    "print(f\"Median wait time: {int(median_waittime)} seconds, {int(median_waittime/60)} minutes\")\n",
    "\n",
    "# 3. What is the average mempool size?\n",
    "avg_mempool_size = txs['mempool_size'].mean()\n",
    "print(f\"Average mempool size: {int(avg_mempool_size)}\")\n",
    "\n",
    "# 4. time window for txs\n",
    "min_found_at = pd.to_datetime(txs['found_at'].min(), unit='s')\n",
    "max_found_at = pd.to_datetime(txs['found_at'].max(), unit='s')\n",
    "print(f\"Time window for txs: {min_found_at} to {max_found_at}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txs['weight'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txs['size'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of wait times\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(txs['waittime'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Wait Times')\n",
    "plt.xlabel('Wait Time (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot txs Fee vs Waittime\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(txs['waittime'], txs['absolute_fee'], alpha=0.3)\n",
    "plt.title('Fee vs Wait Time')\n",
    "plt.xlabel('Wait Time (seconds)')\n",
    "plt.ylabel('Fee (satoshis)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of mempool sizes\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(txs['mempool_size'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Mempool Sizes')\n",
    "plt.xlabel('Mempool Size')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mempool tx count\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(txs['mempool_tx_count'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Mempool Tx Counts')\n",
    "plt.xlabel('Mempool Tx Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mempool size vs waittime\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(txs['mempool_tx_count'], txs['waittime'], alpha=0.3)\n",
    "plt.xlabel('Mempool Tx Count')\n",
    "plt.ylabel('Wait Time (seconds)')\n",
    "plt.title('Mempool Tx Count vs Wait Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove the weird tail of the distribution\n",
    "# txs = txs[txs['mempool_tx_count'] <= 14_000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute heat map of mempool tx count vs waittime\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(txs['mempool_tx_count'], txs['waittime'], alpha=0.3)\n",
    "plt.xlabel('Mempool Tx Count')\n",
    "plt.ylabel('Wait Time (seconds)')\n",
    "plt.title('Mempool Tx Count vs Wait Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardize features since they're on very different scales\n",
    "scaler = StandardScaler()\n",
    "X = txs[['mempool_tx_count', 'mempool_size', 'absolute_fee']]\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = txs['waittime']\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit KNN regressor\n",
    "knn = KNeighborsRegressor(n_neighbors=50, weights='distance')\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Calculate R² scores\n",
    "train_r2 = knn.score(X_train, y_train)\n",
    "test_r2 = knn.score(X_test, y_test)\n",
    "print(f\"Train R² = {train_r2:.4f}\")\n",
    "print(f\"Test R² = {test_r2:.4f}\")\n",
    "\n",
    "# Plot observed vs predicted\n",
    "y_pred = knn.predict(X_scaled)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y, y_pred, alpha=0.3)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.xlabel('Observed wait-time (seconds)')\n",
    "plt.ylabel('Predicted wait-time (seconds)')\n",
    "plt.title(f'KNN Regression (Train R²={train_r2:.2f}, Test R²={test_r2:.2f})')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = txs[['mempool_tx_count', 'mempool_size', 'absolute_fee']]\n",
    "y = txs['waittime']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train,\n",
    "          eval_set=[(X_test, y_test)],\n",
    "          verbose=False)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"True values\")\n",
    "plt.ylabel(\"Predicted values\")\n",
    "plt.title(\"XGBoost Regression Performance\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = txs[['mempool_size', 'absolute_fee']]\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = txs['waittime']\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Calculate R² scores\n",
    "train_r2 = model.score(X_train, y_train)\n",
    "test_r2 = model.score(X_test, y_test)\n",
    "print(f\"Train R² = {train_r2:.4f}\")\n",
    "print(f\"Test R² = {test_r2:.4f}\")\n",
    "\n",
    "# Plot observed vs predicted\n",
    "y_pred = model.predict(X_scaled)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y, y_pred, alpha=0.3)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--', lw=2)\n",
    "plt.xlabel('Observed wait-time (seconds)')\n",
    "plt.ylabel('Predicted wait-time (seconds)')\n",
    "plt.title(f'Linear Regression (Train R²={train_r2:.2f}, Test R²={test_r2:.2f})')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X = txs[['mempool_tx_count', 'mempool_size', 'absolute_fee']]\n",
    "y = txs['waittime']\n",
    "# 2. Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 3. Initialize and train Random Forest\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse:.4f}\")\n",
    "print(f\"Test R^2: {r2:.4f}\")\n",
    "\n",
    "# 6. Optional: Plot predicted vs true\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Random Forest Regression Performance\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
